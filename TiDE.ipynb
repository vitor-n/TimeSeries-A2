{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866c5225",
   "metadata": {},
   "source": [
    "# TiDE vs PatchTST vs AR(1)\n",
    "Fluxo sem Darts: NeuralForecast (TiDE/PatchTST) + statsmodels AR(1). Horizonte=4, walk-forward. Dependências: numpy<2, neuralforecast, pytorch-lightning, statsmodels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78391e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"numpy<2.0\" neuralforecast pytorch-lightning statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13daf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import TiDE, PatchTST\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "HORIZON = 4\n",
    "INITIAL_TRAIN = 104\n",
    "SEASONALITY = 52\n",
    "TEST_SIZE = 30\n",
    "RANDOM_STATE = 42\n",
    "FREQUENCY = \"W-MON\"\n",
    "\n",
    "# Carrega dados\n",
    "\n",
    "df = pd.read_csv(\"data_updated.csv\")\n",
    "df[\"week\"] = pd.to_datetime(df[\"week\"])\n",
    "df = df.sort_values(\"week\").reset_index(drop=True)\n",
    "\n",
    "df_nf = df.rename(columns={\"week\": \"ds\", \"volume\": \"y\"})\n",
    "df_nf[\"unique_id\"] = \"series\"\n",
    "df_nf[\"month\"] = df_nf[\"ds\"].dt.month.astype(int)\n",
    "df_nf[\"weekofyear\"] = df_nf[\"ds\"].dt.isocalendar().week.astype(int)\n",
    "FUTR_EXOG = [\"month\", \"weekofyear\", \"inv\", \"users\"]\n",
    "\n",
    "train_end_idx = len(df_nf) - TEST_SIZE\n",
    "y_values = df_nf[\"y\"].values.astype(np.float32)\n",
    "y_holdout = y_values[train_end_idx:]\n",
    "\n",
    "futr_base = df_nf[[\"unique_id\", \"ds\"] + FUTR_EXOG]\n",
    "\n",
    "\n",
    "def calculate_mase(y_true, y_pred, y_train, m=SEASONALITY):\n",
    "    naive_errors = np.abs(y_train[m:] - y_train[:-m])\n",
    "    mae_naive = np.mean(naive_errors)\n",
    "    if mae_naive < 1e-6 or np.isnan(mae_naive):\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(y_true - y_pred)) / mae_naive\n",
    "\n",
    "\n",
    "def build_tide(params):\n",
    "    return TiDE(\n",
    "        h=HORIZON,\n",
    "        input_size=params[\"input_size\"],\n",
    "        hidden_size=params[\"hidden_size\"],\n",
    "        dropout=params[\"dropout\"],\n",
    "        num_encoder_layers=params[\"num_layers\"],\n",
    "        num_decoder_layers=params[\"num_layers\"],\n",
    "        futr_exog_list=FUTR_EXOG,\n",
    "        learning_rate=params[\"lr\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        max_steps=params[\"max_steps\"],\n",
    "        val_check_steps=params.get(\"val_check_steps\", 100),\n",
    "        random_seed=RANDOM_STATE,\n",
    "        alias=\"TiDE\",\n",
    "    )\n",
    "\n",
    "\n",
    "def build_patch(params):\n",
    "    # PatchTST não suporta exógenas futuras nesta versão; usamos univariado\n",
    "    return PatchTST(\n",
    "        h=HORIZON,\n",
    "        input_size=params[\"input_size\"],\n",
    "        encoder_layers=params[\"encoder_layers\"],\n",
    "        n_heads=params[\"n_heads\"],\n",
    "        hidden_size=params[\"hidden_size\"],\n",
    "        patch_len=params[\"patch_len\"],\n",
    "        stride=params[\"stride\"],\n",
    "        dropout=params[\"dropout\"],\n",
    "        fc_dropout=params[\"dropout\"],\n",
    "        learning_rate=params[\"lr\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        max_steps=params[\"max_steps\"],\n",
    "        val_check_steps=params.get(\"val_check_steps\", 100),\n",
    "        random_seed=RANDOM_STATE,\n",
    "        alias=\"PatchTST\",\n",
    "    )\n",
    "\n",
    "\n",
    "def grid_search_nf(builder, grid, df_nf, futr_base, train_end_idx, y_holdout, use_futr):\n",
    "    train_df = df_nf.iloc[:train_end_idx]\n",
    "    futr_holdout = futr_base.iloc[train_end_idx : train_end_idx + len(y_holdout)] if use_futr else None\n",
    "\n",
    "    best_params, best_mae = None, np.inf\n",
    "    for params in grid:\n",
    "        model = builder(params)\n",
    "        nf = NeuralForecast(models=[model], freq=FREQUENCY)\n",
    "        nf.fit(df=train_df, val_size=0, verbose=False)\n",
    "        if use_futr:\n",
    "            preds_df = nf.predict(futr_df=futr_holdout, h=len(y_holdout), verbose=False)\n",
    "        else:\n",
    "            preds_df = nf.predict(h=len(y_holdout), verbose=False)\n",
    "        y_pred = preds_df[model.alias].values\n",
    "        mae = np.mean(np.abs(y_holdout - y_pred))\n",
    "        print(f\"{model.alias} params {params} | MAE holdout: {mae:.4f}\")\n",
    "        if mae < best_mae:\n",
    "            best_params, best_mae = params, mae\n",
    "    return best_params, best_mae\n",
    "\n",
    "\n",
    "def grid_search_ar1():\n",
    "    y_train = y_values[:train_end_idx]\n",
    "    model = ARIMA(y_train, order=(1, 0, 0)).fit()\n",
    "    preds = model.forecast(steps=len(y_holdout))\n",
    "    mae = np.mean(np.abs(y_holdout - preds))\n",
    "    print(f\"AR(1) MAE holdout: {mae:.4f}\")\n",
    "    return {}, mae\n",
    "\n",
    "\n",
    "def run_walk_forward_nf(builder, params, alias, df_nf, futr_base, y_values, use_futr):\n",
    "    rows = []\n",
    "    for cutoff in range(INITIAL_TRAIN, len(df_nf) - HORIZON + 1):\n",
    "        train_df = df_nf.iloc[:cutoff]\n",
    "        futr_df = futr_base.iloc[cutoff : cutoff + HORIZON] if use_futr else None\n",
    "        target = y_values[cutoff : cutoff + HORIZON]\n",
    "        train_values = y_values[:cutoff]\n",
    "\n",
    "        model = builder(params)\n",
    "        nf = NeuralForecast(models=[model], freq=FREQUENCY)\n",
    "        nf.fit(df=train_df, val_size=0, verbose=False)\n",
    "        if use_futr:\n",
    "            preds_df = nf.predict(futr_df=futr_df, h=HORIZON, verbose=False)\n",
    "        else:\n",
    "            preds_df = nf.predict(h=HORIZON, verbose=False)\n",
    "        preds = preds_df[model.alias].values\n",
    "        cutoff_time = train_df[\"ds\"].iloc[-1]\n",
    "\n",
    "        for h in range(HORIZON):\n",
    "            mase = calculate_mase(target[h], preds[h], train_values, m=SEASONALITY)\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"model\": alias,\n",
    "                    \"cutoff\": cutoff_time,\n",
    "                    \"horizon\": h + 1,\n",
    "                    \"y_true\": target[h],\n",
    "                    \"y_pred\": preds[h],\n",
    "                    \"abs_error\": abs(target[h] - preds[h]),\n",
    "                    \"mase\": mase,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def run_walk_forward_ar1():\n",
    "    rows = []\n",
    "    for cutoff in range(INITIAL_TRAIN, len(df_nf) - HORIZON + 1):\n",
    "        train = y_values[:cutoff]\n",
    "        target = y_values[cutoff : cutoff + HORIZON]\n",
    "        cutoff_time = df_nf[\"ds\"].iloc[cutoff - 1]\n",
    "        try:\n",
    "            model = ARIMA(train, order=(1, 0, 0)).fit()\n",
    "            preds = model.forecast(steps=HORIZON)\n",
    "        except Exception:\n",
    "            preds = np.repeat(train[-1], HORIZON)\n",
    "        for h in range(HORIZON):\n",
    "            mase = calculate_mase(target[h], preds[h], train, m=SEASONALITY)\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"model\": \"AR(1)\",\n",
    "                    \"cutoff\": cutoff_time,\n",
    "                    \"horizon\": h + 1,\n",
    "                    \"y_true\": target[h],\n",
    "                    \"y_pred\": preds[h],\n",
    "                    \"abs_error\": abs(target[h] - preds[h]),\n",
    "                    \"mase\": mase,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_metrics(df_metrics):\n",
    "    return (\n",
    "        df_metrics.groupby([\"model\", \"horizon\"])\n",
    "        .agg(MAE=(\"abs_error\", \"mean\"), MASE=(\"mase\", \"mean\"))\n",
    "        .reset_index()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_param_grid = [\n",
    "    {\n",
    "        \"input_size\": 26,\n",
    "        \"hidden_size\": 256,\n",
    "        \"dropout\": 0.15,\n",
    "        \"num_layers\": 2,\n",
    "        \"lr\": 1e-3,\n",
    "        \"batch_size\": 32,\n",
    "        \"max_steps\": 400,\n",
    "        \"val_check_steps\": 50,\n",
    "    }\n",
    "]\n",
    "\n",
    "patch_param_grid = [\n",
    "    {\n",
    "        \"input_size\": 36,\n",
    "        \"patch_len\": 6,\n",
    "        \"stride\": 3,\n",
    "        \"encoder_layers\": 3,\n",
    "        \"n_heads\": 8,\n",
    "        \"hidden_size\": 128,\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 1e-3,\n",
    "        \"batch_size\": 32,\n",
    "        \"max_steps\": 400,\n",
    "        \"val_check_steps\": 50,\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Grid TiDE: {len(tide_param_grid)} combinação(s)\")\n",
    "best_tide_params, tide_holdout = grid_search_nf(build_tide, tide_param_grid, df_nf, futr_base, train_end_idx, y_holdout, use_futr=True)\n",
    "\n",
    "print(f\"Grid PatchTST: {len(patch_param_grid)} combinação(s)\")\n",
    "best_patch_params, patch_holdout = grid_search_nf(build_patch, patch_param_grid, df_nf, futr_base, train_end_idx, y_holdout, use_futr=False)\n",
    "\n",
    "print(\"Grid AR(1): 1 combinação\")\n",
    "best_ar1_params, ar1_holdout = grid_search_ar1()\n",
    "\n",
    "print(f\"Melhor TiDE: {best_tide_params} | MAE holdout={tide_holdout:.4f}\")\n",
    "print(f\"Melhor PatchTST: {best_patch_params} | MAE holdout={patch_holdout:.4f}\")\n",
    "print(f\"Baseline AR(1) MAE holdout={ar1_holdout:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rodando walk-forward TiDE...\")\n",
    "df_tide = run_walk_forward_nf(build_tide, best_tide_params, \"TiDE\", df_nf, futr_base, y_values, use_futr=True)\n",
    "\n",
    "print(\"Rodando walk-forward PatchTST...\")\n",
    "df_patch = run_walk_forward_nf(build_patch, best_patch_params, \"PatchTST\", df_nf, futr_base, y_values, use_futr=False)\n",
    "\n",
    "print(\"Rodando walk-forward AR(1)...\")\n",
    "df_ar1 = run_walk_forward_ar1()\n",
    "\n",
    "df_all = pd.concat([df_tide, df_patch, df_ar1], ignore_index=True)\n",
    "metrics = summarize_metrics(df_all)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ad8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(df[\"week\"], df[\"volume\"], label=\"Real\", color=\"black\", alpha=0.4)\n",
    "\n",
    "h1_tide = df_tide[df_tide[\"horizon\"] == 1]\n",
    "ax.plot(h1_tide[\"cutoff\"], h1_tide[\"y_pred\"], label=\"TiDE h=1\", color=\"blue\")\n",
    "\n",
    "h1_patch = df_patch[df_patch[\"horizon\"] == 1]\n",
    "ax.plot(h1_patch[\"cutoff\"], h1_patch[\"y_pred\"], label=\"PatchTST h=1\", color=\"green\")\n",
    "\n",
    "h1_ar1 = df_ar1[df_ar1[\"horizon\"] == 1]\n",
    "ax.plot(h1_ar1[\"cutoff\"], h1_ar1[\"y_pred\"], label=\"AR(1) h=1\", color=\"red\", alpha=0.7)\n",
    "\n",
    "ax.set_title(\"Walk-forward horizonte 1\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
